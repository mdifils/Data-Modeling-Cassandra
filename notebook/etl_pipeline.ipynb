{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f57279e-a493-47a6-a0ff-ab9e269f48ae",
   "metadata": {},
   "source": [
    "### Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083feb2f-9332-416b-bf24-885d3ac47762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e30a0-52eb-4eab-9e5b-a94dc2a0f236",
   "metadata": {},
   "source": [
    "## Connection To Apache Cassandra\n",
    "\n",
    "Remember that cassandra service in docker-compose.yml file was defined as 'cassandra_node'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b952a893-fa51-4a7a-a535-b5311f73d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(['cassandra_node'])\n",
    "\n",
    "# Setting a session to be able to execute queries\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d7a98-82d7-4402-96e9-220e4afd254c",
   "metadata": {},
   "source": [
    "### Dropping tables if keyspace exists or creating a new keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72aabd0-d972-4009-98a6-5251155a0aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping length_playlist_session ...\n",
      "Dropping user_playlist_session ...\n",
      "Dropping song_user ...\n"
     ]
    }
   ],
   "source": [
    "# If keyspace exists drop tables\n",
    "try:\n",
    "    session.set_keyspace('sparkify_ks')\n",
    "    for tab in ['length_playlist_session', 'user_playlist_session', 'song_user']:\n",
    "        query = f\"DROP TABLE IF EXISTS sparkify.{tab}\"\n",
    "        session.execute(query)\n",
    "        print(f\"Dropping {tab} ...\")\n",
    "\n",
    "# If keyspace doesn't exists, create a new one\n",
    "except:\n",
    "    # creating a new keyspace\n",
    "    session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS sparkify_ks\n",
    "        WITH REPLICATION = {\n",
    "            'class' : 'SimpleStrategy',\n",
    "            'replication_factor' : 1\n",
    "        }\"\"\"\n",
    "                    )\n",
    "    print(\"KEYSPACE sparkify_ks created\")\n",
    "    # setting the new created keyspace\n",
    "    session.set_keyspace('sparkify_ks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40e819-b580-4908-823e-3e2c49df7877",
   "metadata": {},
   "source": [
    "### LOADING DATA INTO DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f31aa51-59b3-4c5d-901b-0f69f1fafc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_dataframe(dataset_folder: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - This function takes as input a string representing the data folder.\n",
    "    - It returns a dataframe that contains all data extracted from all CSV files\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the current working directory\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # Set the folder path of all files\n",
    "    files_folderpath = cwd + dataset_folder\n",
    "\n",
    "    # Get the list of filename\n",
    "    filename_list = os.listdir(files_folderpath)\n",
    "\n",
    "    # number of all CSV files\n",
    "    num_files = len(filename_list)\n",
    "    print(f'{num_files} files found')\n",
    "\n",
    "    # I'm going to associate a dataframe to every csv file\n",
    "    # Then I'm going to put all those dataframes into a list\n",
    "    # Finally I'm going stack or concatenate vertically all\n",
    "    # dataframes into a single big dataframe which will have\n",
    "    # the same number of columns but the number of rows will\n",
    "    # be the sum of all dataframes.\n",
    "    df_list = []\n",
    "\n",
    "    # Every csv file has the same number of columns but here are\n",
    "    # the interesting ones\n",
    "    column_list = ['artist', 'firstName', 'gender', 'itemInSession', 'lastName',\n",
    "                   'length', 'level', 'location', 'sessionId', 'song', 'userId']\n",
    "\n",
    "    for i, item in enumerate(filename_list, 1):\n",
    "\n",
    "        # Joinning each filename with files_folderpath to get filepath\n",
    "        filepath = os.path.join(files_folderpath, item)\n",
    "\n",
    "        # each file is associated to a dataframe\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        # Taking only interesting columns\n",
    "        df = df[column_list]\n",
    "\n",
    "        # Appending each dataframe to the list\n",
    "        df_list.append(df)\n",
    "        print(f'{i}/{num_files} files processed')\n",
    "\n",
    "    # Putting all dataframes together\n",
    "    all_files_dataframe = pd.concat(df_list, ignore_index=True, axis=0)\n",
    "\n",
    "    return all_files_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17df4e86-1e8a-4ee3-83a0-852c6e8f6a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 files found\n",
      "1/30 files processed\n",
      "2/30 files processed\n",
      "3/30 files processed\n",
      "4/30 files processed\n",
      "5/30 files processed\n",
      "6/30 files processed\n",
      "7/30 files processed\n",
      "8/30 files processed\n",
      "9/30 files processed\n",
      "10/30 files processed\n",
      "11/30 files processed\n",
      "12/30 files processed\n",
      "13/30 files processed\n",
      "14/30 files processed\n",
      "15/30 files processed\n",
      "16/30 files processed\n",
      "17/30 files processed\n",
      "18/30 files processed\n",
      "19/30 files processed\n",
      "20/30 files processed\n",
      "21/30 files processed\n",
      "22/30 files processed\n",
      "23/30 files processed\n",
      "24/30 files processed\n",
      "25/30 files processed\n",
      "26/30 files processed\n",
      "27/30 files processed\n",
      "28/30 files processed\n",
      "29/30 files processed\n",
      "30/30 files processed\n"
     ]
    }
   ],
   "source": [
    "def transform(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - Takes dataframe as input and returns a transformed dataframe\n",
    "    - renames some columns to meet PEP8 requirements\n",
    "    - Handles NaN for columns of type object (string) \n",
    "    \"\"\"\n",
    "    # Renaming column names\n",
    "    df.rename(columns={'firstName': 'first_name',\n",
    "                       'itemInSession': 'item_in_session',\n",
    "                                        'lastName': 'last_name',\n",
    "                                        'sessionId': 'session_id',\n",
    "                                        'userId': 'user_id'}, inplace=True)\n",
    "\n",
    "    # Converting NaN into empty string for columns of type object\n",
    "    # pandas type 'object' means the column values are strings\n",
    "    # NaN (not a number or null value) is a float (numpy.nan).\n",
    "    # So when inserting values into tables Cassandra will complain\n",
    "    # for not being able to convert NaN as text\n",
    "\n",
    "    # Get the list of dataframe columns\n",
    "    cols = df.columns\n",
    "    for col in cols:\n",
    "        if df.dtypes[col] == object:\n",
    "            # if the type of column is object then replace\n",
    "            # all NaN by empty string\n",
    "            df[col] = df[col].replace(np.nan, '')\n",
    "\n",
    "    # Replace NaN in user_id column by 0\n",
    "    # So user_id=0 means null value then\n",
    "    df['user_id'] = df['user_id'].fillna(0)\n",
    "    # Then converting user_id from float to integer type\n",
    "    df['user_id'] = df['user_id'].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = files_to_dataframe('/event_data')\n",
    "df = transform(df)\n",
    "\n",
    "# I could convert this dataframe into CSV\n",
    "# --df.to_csv('event_data_new.csv', index=False, encoding='utf-8')---\n",
    "# but I won't use it because I prefer to work with dataframe only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97a443-ee04-4bfb-a91b-868ee6db889b",
   "metadata": {},
   "source": [
    "### PROCESSING FIRST QUERY\n",
    "\n",
    "#### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac184b7-e81b-4947-b07c-d88e5c0380ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING length_playlist_session table\n"
     ]
    }
   ],
   "source": [
    "print(\"CREATING length_playlist_session table\")\n",
    "\n",
    "# -------------------CREATING TABLE----------------------------------\n",
    "\n",
    "select_query1 = \"\"\"\n",
    "    SELECT artist, song, length \n",
    "    FROM length_playlist_session\n",
    "    WHERE session_id = 338 AND item_in_session = 4\n",
    "\"\"\"\n",
    "\n",
    "# The WHERE clause gives us the table composite key\n",
    "\n",
    "create_query1 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS length_playlist_session(\n",
    "        session_id int, \n",
    "        item_in_session int, \n",
    "        artist text, \n",
    "        song text,\n",
    "        length float,\n",
    "        PRIMARY KEY(session_id, item_in_session)\n",
    "    )\"\"\"\n",
    "try:\n",
    "    session.execute(create_query1)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82df771d-cffc-49f9-b73e-6cd64ae6032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERTING INTO length_playlist_session\n"
     ]
    }
   ],
   "source": [
    "print(\"INSERTING INTO length_playlist_session\")\n",
    "\n",
    "# ------------------------INSERTING INTO TABLE-------------------------\n",
    "\n",
    "insert_query1 = \"\"\"\n",
    "    INSERT INTO length_playlist_session\n",
    "    (session_id, item_in_session, artist, song, length)\n",
    "    VALUES (%s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Iteracting over each row of the dataframe\n",
    "for i, row in df.iterrows():\n",
    "    # for each row, just take interested valuess\n",
    "    data = (row.session_id, row.item_in_session,\n",
    "            row.artist, row.song, row.length)\n",
    "    session.execute(insert_query1, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282909db-a2b8-4969-9593-2a140d4d743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING FIRST QUERY\n",
      "\n",
      "QUERY 1:\n",
      "\n",
      "    Give me the artist, song title and song's length in the music app \n",
      "    history that was heard during sessionId = 338, and itemInSession = 4\n",
      "\n",
      "\n",
      "ARTIST                SONG                                                    LENGTH\n",
      "\n",
      "Faithless            Music Matters (Mark Knight Dub)                         495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING FIRST QUERY\\n\")\n",
    "\n",
    "# -----------------------TESTING-------------------------------------\n",
    "\n",
    "try:\n",
    "    rows = session.execute(select_query1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"\"\"QUERY 1:\\n\n",
    "    Give me the artist, song title and song's length in the music app \n",
    "    history that was heard during sessionId = 338, and itemInSession = 4\n",
    "\\n\"\"\")\n",
    "\n",
    "print(f\"{'ARTIST' :<20}  {'SONG':<55} LENGTH\\n\")\n",
    "\n",
    "for row in rows:\n",
    "    print(f\"{row.artist:<20} {row.song:<55} {row.length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d9017-2369-4e79-929a-430cccb112f6",
   "metadata": {},
   "source": [
    "### PROCESSING SECOND QUERY\n",
    "\n",
    "#### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bda411e5-a4ef-4e3b-9893-dacb48f77a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING user_playlist_session table\n"
     ]
    }
   ],
   "source": [
    "print(\"CREATING user_playlist_session table\")\n",
    "\n",
    "# ----------------------CREATING TABLE-------------------------------------\n",
    "\n",
    "select_query2 = \"\"\"\n",
    "    SELECT artist, song, first_name, last_name \n",
    "    FROM user_playlist_session\n",
    "    WHERE user_id = 10 AND session_id = 182\n",
    "\"\"\"\n",
    "\n",
    "# The WHERE clause gives us the table composite partition key \n",
    "# (user_id,session_id) Then adding one more clustering column item_in_session\n",
    "# for sorting reason\n",
    "\n",
    "create_query2 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS user_playlist_session(\n",
    "        user_id float, \n",
    "        session_id int, \n",
    "        item_in_session int,\n",
    "        artist text, \n",
    "        song text, \n",
    "        first_name text, \n",
    "        last_name text,\n",
    "        PRIMARY KEY((user_id, session_id), item_in_session)\n",
    "    )\"\"\"\n",
    "try:\n",
    "    session.execute(create_query2)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a877b4-ae2a-4ad4-a913-e18efcf7e45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERTING INTO user_playlist_session\n"
     ]
    }
   ],
   "source": [
    "print(\"INSERTING INTO user_playlist_session\")\n",
    "\n",
    "# ------------------INSERTING INTO TABLE--------------------------------------\n",
    "\n",
    "insert_query2 = \"\"\"\n",
    "    INSERT INTO user_playlist_session\n",
    "    (user_id, session_id, item_in_session,\n",
    "    artist, song, first_name, last_name)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    data = (row.user_id, row.session_id, row.item_in_session,\n",
    "            row.artist, row.song, row.first_name, row.last_name)\n",
    "    session.execute(insert_query2, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "771e3cc0-3d3d-471b-b423-f4644c239374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING SECOND QUERY\n",
      "\n",
      "QUERY 2:\n",
      "\n",
      "    Give me only the following: name of artist, song\n",
      "    (sorted by itemInSession) and user (first and last name)\n",
      "    for userid = 10, sessionid = 182\n",
      "\n",
      "\n",
      "ARTIST                SONG                                                    FIRSTNAME  LASTNAME\n",
      "\n",
      "Down To The Bone     Keep On Keepin' On                                      Sylvie         Cruz\n",
      "Three Drives         Greece 2000                                             Sylvie         Cruz\n",
      "Sebastien Tellier    Kilometer                                               Sylvie         Cruz\n",
      "Lonnie Gordon        Catch You Baby (Steve Pitron & Max Sanna Radio Edit)    Sylvie         Cruz\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING SECOND QUERY\\n\")\n",
    "\n",
    "# -----------------------TESTING--------------------------------\n",
    "\n",
    "try:\n",
    "    rows = session.execute(select_query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"\"\"QUERY 2:\\n\n",
    "    Give me only the following: name of artist, song\n",
    "    (sorted by itemInSession) and user (first and last name)\n",
    "    for userid = 10, sessionid = 182\n",
    "\\n\"\"\")\n",
    "\n",
    "print(f\"{'ARTIST':<20}  {'SONG':<55} {'FIRSTNAME' :<10} LASTNAME\\n\")\n",
    "\n",
    "for row in rows:\n",
    "    print(f\"{row.artist:<20} {row.song:<55} {row.first_name:<10} \\\n",
    "    {row.last_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f88aa-2ee8-43d9-95c1-1d2b69e07f7c",
   "metadata": {},
   "source": [
    "### PROCESSING THIRD QUERY\n",
    "\n",
    "#### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f02b473e-05ea-49d2-8739-ddf3a2495d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING song_user table\n"
     ]
    }
   ],
   "source": [
    "print(\"CREATING song_user table\")\n",
    "\n",
    "# ---------------------CREATING TABLE--------------------------------\n",
    "\n",
    "select_query3 = \"\"\"\n",
    "    SELECT first_name, last_name \n",
    "    FROM song_user\n",
    "    WHERE song = 'All Hands Against His Own'\n",
    "\"\"\"\n",
    "\n",
    "# The WHERE clause gives us our partition key\n",
    "# Then adding user_id as clustering column to make the key unique\n",
    "\n",
    "create_query3 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS song_user(\n",
    "        song text, \n",
    "        user_id float, \n",
    "        first_name text,\n",
    "        last_name text, \n",
    "        PRIMARY KEY(song, user_id)\n",
    "    )\"\"\"\n",
    "try:\n",
    "    session.execute(create_query3)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb310b11-4ac2-4d1e-9c5c-0a092515dde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERTING INTO song_user\n"
     ]
    }
   ],
   "source": [
    "print(\"INSERTING INTO song_user\")\n",
    "# --------------INSERTING INTO TABLE--------------------------------\n",
    "\n",
    "insert_query3 = \"\"\"\n",
    "    INSERT INTO song_user(song, user_id, first_name, last_name)\n",
    "    VALUES (%s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# partition key may not be empty\n",
    "df_query3 = df[df['song'] != '']\n",
    "\n",
    "for i, row in df_query3.iterrows():\n",
    "    data = (row.song, row.user_id, row.first_name, row.last_name)\n",
    "    session.execute(insert_query3, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f512e1-e5a8-4205-9b46-d24c1572a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THIRD QUERY\n",
      "QUERY 3:\n",
      "\n",
      "    Give me every user name (first and last) in my music app\n",
      "    history who listened to the song 'All Hands Against His Own'\n",
      "\n",
      "\n",
      "FIRSTNAME     LASTNAME\n",
      "\n",
      "Jacqueline   Lynch\n",
      "Tegan        Levine\n",
      "Sara         Johnson\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING THIRD QUERY\")\n",
    "# ------------------------------TESTING-------------------------------------\n",
    "\n",
    "try:\n",
    "    rows = session.execute(select_query3)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"\"\"QUERY 3:\\n\n",
    "    Give me every user name (first and last) in my music app\n",
    "    history who listened to the song 'All Hands Against His Own'\n",
    "\\n\"\"\")\n",
    "\n",
    "print(f\"{'FIRSTNAME' :<12}  LASTNAME\\n\")\n",
    "\n",
    "for row in rows:\n",
    "    print(f\"{row.first_name:<12} {row.last_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f180f83-7f09-4ca1-bd9e-a83307c96e7b",
   "metadata": {},
   "source": [
    "### DROP TABLES CLOSING CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66454e35-de2e-426a-973b-75f4dd236d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping length_playlist_session ...\n",
      "Dropping user_playlist_session ...\n",
      "Dropping song_user ...\n"
     ]
    }
   ],
   "source": [
    "# -----------------DROPPING TABLES-------------------------\n",
    "\n",
    "try:\n",
    "    for tab in ['length_playlist_session', 'user_playlist_session', 'song_user']:\n",
    "        query = f\"DROP TABLE IF EXISTS sparkify.{tab}\"\n",
    "        session.execute(query)\n",
    "        print(f\"Dropping {tab} ...\")\n",
    "except:\n",
    "    print(\"Tables are not dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ce8c000-6b2a-4401-a45b-b5384fb9ca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KEYSPACE sparkify_ks dropped\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------DROPPING KEYSPACE------------------------\n",
    "\n",
    "try:\n",
    "    r = session.execute(\"DROP KEYSPACE IF EXISTS sparkify_ks\")\n",
    "    print(\"\\nKEYSPACE sparkify_ks dropped\\n\")\n",
    "except:\n",
    "    print(\"\\nKEYSPACE sparkify_ks not dropped\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ae2ead-84e4-4e29-9fbb-361db5ad2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------CLOSING CONNECTION---------------------\n",
    "\n",
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
